전체 코드 변경 요약 (GitHub `jaehoon` 브랜치 vs 현재 작업본)

1. main.py
- upload_video() 내에서 .mp4 삭제 시 PermissionError를 방지하기 위한 안전 처리 도입
- 구조나 기능은 그대로이며 파일 핸들링 및 파이프라인 호출 유지

2. runner.py
- 음악 생성 함수가 dict 반환 → 직접 .wav 저장 방식으로 변경
- 감성 자막 분석 결과가 단일 문장 → top_caption, top_captions, all_captions 구조로 확장
- 프롬프트 생성 시 보조 자막 활용
- 생성된 .wav 파일 유효성 검사 추가
- Windows 환경에서 리소스 해제 문제 대응 (time.sleep(0.5))

3. blip_emotion_analyzer.py
- 단일 caption → top_caption, top_captions, all_captions 포함한 dict로 반환 구조 확장
- 프롬프트 정제에 활용 가능한 다중 자막 반환

4. llm_prompt_refiner.py
- refine_prompt() 함수가 raw_caption 단일 입력 → top_caption + top_captions로 확장
- 감정 프롬프트를 영어로 출력하도록 명시 (한국어로 prompt 생성시, musicgen이 정확한 의도를 받지 못함)
- 응답 검증 추가 (빈 결과/짧은 문장 필터링, 여러 줄 중 첫 줄 사용)

5. music_generator.py
- cuda 사용유도로 속도 향상
- transformers 기반 MusicgenForConditionalGeneration → audiocraft MusicGen으로 모델 변경
    📌 Musicgen 비교 요약 (Transformers vs Audiocraft)

    [1] MusicgenForConditionalGeneration (🤗 Hugging Face)
    - 설치: pip install transformers
    - 불러오기: from transformers import MusicgenForConditionalGeneration
    - 장점: 사용 간편, Hugging Face pipeline 호환
    - 단점: 기능 제한 (duration 설정, 채널 조정, 고급 sampling 불가)
    - 용도: 간단한 테스트, 빠른 프로토타입

    [2] audiocraft.models.MusicGen (🎧 Meta 공식)
    - 설치: pip install audiocraft
    - 불러오기: from audiocraft.models import MusicGen
    - 장점: Meta 원본 기능 100% 제공, 고급 설정 가능 (sampling, duration, stereo 등)
    - 단점: transformers pipeline과는 별도로 사용
    - 용도: 실전 서비스, 커스터마이즈된 음악 생성

    ✅ 요약:
    - 간단한 실험 = Hugging Face 버전
    - 실전 성능과 제어 필요 = Meta Audiocraft 버전

- 오디오 생성 방식 변경: 반환 대신 .wav 파일 직접 저장
- stereo → mono 변환, float → int16 클리핑 처리로 호환성 확보
- wav_write 저장 중 오류 방지를 위한 안전 변환 포함
- 상세한 생성 로그 출력 추가

- 전체 파이프라인이 더 견고하고 실용적으로 변경되었음
- 감정 해석 → 프롬프트 생성 → 음악 생성 → 영상 병합 흐름이 정교하게 연결됨

*추가사항 : pip install git+https://github.com/facebookresearch/audiocraft#egg=audiocraft
